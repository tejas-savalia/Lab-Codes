{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "## States: A continuous function of r and theta. Goal State: r = dist. theta = Theta\n",
    "## Actions: delta_r, delta_theta\n",
    "## Reward: -1 for every action. +100 to reach the goal state.\n",
    "## Transition Prob: s, a, s' = 1. s' changes based on condition\n",
    "### Environment takes a state action pair and returns reward and new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 50\n",
    "Theta = 45\n",
    "def step_environment(state, action):\n",
    "    goal_state = numpy.array([dist, Theta])\n",
    "    r, theta = state\n",
    "    delta_r, delta_theta = action\n",
    "    state = numpy.array([r+delta_r, theta+delta_theta])\n",
    "    if numpy.array_equal(state, goal_state):\n",
    "        reward = 100\n",
    "    #Put end condition here\n",
    "    else:\n",
    "        reward = -1\n",
    "    if reward == 100:\n",
    "        print (\"Episode complete\")\n",
    "        state = numpy.zeros((1, 2))\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode complete\n"
     ]
    }
   ],
   "source": [
    "new_state, reward = step_environment(numpy.array([49, 43]), numpy.array([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State [2.77926869 1.19209363]\n",
      "Reward -1\n",
      "State [4.25025488 2.10724777]\n",
      "Reward -1\n",
      "State [5.48090031 2.49067942]\n",
      "Reward -1\n",
      "State [7.66628933 2.13338868]\n",
      "Reward -1\n",
      "State [9.44758148 1.07845915]\n",
      "Reward -1\n",
      "State [10.81193158  2.70447072]\n",
      "Reward -1\n",
      "State [12.81026825  5.394466  ]\n",
      "Reward -1\n",
      "State [12.4254178   5.72824929]\n",
      "Reward -1\n",
      "State [13.70360207  7.36277049]\n",
      "Reward -1\n",
      "State [14.31744847  7.89142111]\n",
      "Reward -1\n",
      "State [14.68823101  9.31773064]\n",
      "Reward -1\n",
      "State [15.53297944 10.0486728 ]\n",
      "Reward -1\n",
      "State [16.65989892 12.37521576]\n",
      "Reward -1\n",
      "State [17.76029589 11.12095099]\n",
      "Reward -1\n",
      "State [18.1137172  14.25735118]\n",
      "Reward -1\n",
      "State [20.18603684 16.14680392]\n",
      "Reward -1\n",
      "State [21.10010043 15.09298806]\n",
      "Reward -1\n",
      "State [22.93742908 15.55633707]\n",
      "Reward -1\n",
      "State [23.4540131  15.91457941]\n",
      "Reward -1\n",
      "State [25.89927899 16.4245928 ]\n",
      "Reward -1\n",
      "State [26.68451382 17.61253022]\n",
      "Reward -1\n",
      "State [28.19380432 19.78354114]\n",
      "Reward -1\n",
      "State [28.02341238 21.62964903]\n",
      "Reward -1\n",
      "State [28.24536908 22.14533707]\n",
      "Reward -1\n",
      "State [30.57848821 22.5325374 ]\n",
      "Reward -1\n",
      "State [31.607819   24.03486638]\n",
      "Reward -1\n",
      "State [32.4849334  25.13812357]\n",
      "Reward -1\n",
      "State [33.2731689  27.28483781]\n",
      "Reward -1\n",
      "State [35.4553761  29.11414795]\n",
      "Reward -1\n",
      "State [35.44955703 28.36131327]\n",
      "Reward -1\n",
      "State [36.09543406 30.78629064]\n",
      "Reward -1\n",
      "State [38.66924819 30.63184699]\n",
      "Reward -1\n",
      "State [40.07147874 32.55238879]\n",
      "Reward -1\n",
      "State [40.8014674  32.90537792]\n",
      "Reward -1\n",
      "State [41.45130957 35.43583464]\n",
      "Reward -1\n",
      "State [42.36001938 36.82073389]\n",
      "Reward -1\n",
      "State [44.95171987 38.32977861]\n",
      "Reward -1\n",
      "State [44.5198598 38.2646806]\n",
      "Reward -1\n",
      "State [46.35625033 38.73599497]\n",
      "Reward -1\n",
      "State [47.41610761 40.31879204]\n",
      "Reward -1\n",
      "State [48.36896778 42.54472658]\n",
      "Reward -1\n",
      "State [50.04584782 40.73725563]\n",
      "Reward -1\n",
      "State [49.78000055 42.10931741]\n",
      "Reward -1\n",
      "State [49.93690885 42.32070938]\n",
      "Reward -1\n",
      "State [51.71722428 42.67507708]\n",
      "Reward -1\n",
      "State [53.82874567 44.5507743 ]\n",
      "Reward -1\n",
      "State [53.69355669 44.94784497]\n",
      "Reward -1\n",
      "State [52.95996385 47.08791965]\n",
      "Reward -1\n",
      "State [54.92581152 47.59760309]\n",
      "Reward -1\n",
      "State [56.51768306 50.21776692]\n",
      "Reward -1\n",
      "State [58.98147606 50.4068612 ]\n",
      "Reward -1\n",
      "State [61.29407602 50.29567746]\n",
      "Reward -1\n",
      "State [64.57302737 52.50829894]\n",
      "Reward -1\n",
      "State [65.8896604  51.07539003]\n",
      "Reward -1\n",
      "State [67.23208598 52.33322409]\n",
      "Reward -1\n",
      "State [67.86199357 54.76758464]\n",
      "Reward -1\n",
      "State [69.40158793 55.71608675]\n",
      "Reward -1\n",
      "State [70.87527015 57.52283438]\n",
      "Reward -1\n",
      "State [73.73972532 59.12272802]\n",
      "Reward -1\n",
      "State [75.66556778 61.02099123]\n",
      "Reward -1\n",
      "State [75.95060362 62.70087304]\n",
      "Reward -1\n",
      "State [77.58133261 63.31025729]\n",
      "Reward -1\n",
      "State [77.99955271 63.99592207]\n",
      "Reward -1\n",
      "State [79.94965606 65.43631969]\n",
      "Reward -1\n",
      "State [80.28900441 66.13759622]\n",
      "Reward -1\n",
      "State [82.63907913 66.98061571]\n",
      "Reward -1\n",
      "State [84.05418859 68.30893412]\n",
      "Reward -1\n",
      "State [84.8960571  69.44658265]\n",
      "Reward -1\n",
      "State [85.66800235 69.87612036]\n",
      "Reward -1\n",
      "State [86.65374658 72.08661081]\n",
      "Reward -1\n",
      "State [87.44716205 72.96646771]\n",
      "Reward -1\n",
      "State [87.5746288  75.31489582]\n",
      "Reward -1\n",
      "State [88.55641469 76.23602183]\n",
      "Reward -1\n",
      "State [88.25908938 76.71126968]\n",
      "Reward -1\n",
      "State [91.60365544 77.41259198]\n",
      "Reward -1\n",
      "State [91.44530382 77.59837445]\n",
      "Reward -1\n",
      "State [92.0067114  77.43530968]\n",
      "Reward -1\n",
      "State [91.97338607 77.56734319]\n",
      "Reward -1\n",
      "State [94.12664243 79.04433454]\n",
      "Reward -1\n",
      "State [94.39610018 80.67740363]\n",
      "Reward -1\n",
      "State [95.40079875 81.71061171]\n",
      "Reward -1\n",
      "State [96.35280982 81.67179802]\n",
      "Reward -1\n",
      "State [97.29412398 84.35241784]\n",
      "Reward -1\n",
      "State [97.56514931 86.71123495]\n",
      "Reward -1\n",
      "State [99.28263042 86.64327925]\n",
      "Reward -1\n",
      "State [101.50231151  87.72756516]\n",
      "Reward -1\n",
      "State [102.93410772  88.03324127]\n",
      "Reward -1\n",
      "State [103.47749019  88.08153894]\n",
      "Reward -1\n",
      "State [103.79005513  89.66786413]\n",
      "Reward -1\n",
      "State [105.24179068  90.706933  ]\n",
      "Reward -1\n",
      "State [107.87840269  91.91063552]\n",
      "Reward -1\n",
      "State [109.17285608  93.13048269]\n",
      "Reward -1\n",
      "State [109.46771398  94.15178795]\n",
      "Reward -1\n",
      "State [109.31928849  96.12140155]\n",
      "Reward -1\n",
      "State [109.76050965  95.89751982]\n",
      "Reward -1\n",
      "State [110.87746907  95.33726623]\n",
      "Reward -1\n",
      "State [113.29192114  97.45208337]\n",
      "Reward -1\n",
      "State [114.54489446  99.37897508]\n",
      "Reward -1\n",
      "State [118.00586495 101.51760146]\n",
      "Reward -1\n",
      "State [118.60423655 102.6035388 ]\n",
      "Reward -1\n"
     ]
    }
   ],
   "source": [
    "state = numpy.array([0, 0])\n",
    "for _ in range(100):\n",
    "    state, reward = step_environment(state, numpy.random.normal(1, 1, 2))\n",
    "    print (\"State\", state)\n",
    "    print (\"Reward\", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
