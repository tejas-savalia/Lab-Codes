{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import pickle\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "from sklearn.metrics import *\n",
    "import scipy.stats as stat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Transfer (4 Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_model_sudden_transfer(num_trials, Af, Bf, As, Bs):\n",
    "    errors = np.zeros((num_trials))\n",
    "    rotation = 1.0\n",
    "    fast_est = np.zeros((num_trials))\n",
    "    slow_est = np.zeros((num_trials))\n",
    "    rotation_est = np.zeros((num_trials))\n",
    "    #rotation_est[0] = est\n",
    "    for trial in range(num_trials - 1):\n",
    "        if trial < 640:\n",
    "            rotation = 1.0\n",
    "            errors[trial] = rotation - rotation_est[trial]\n",
    "            fast_est[trial+1] = Af*fast_est[trial] + Bf*errors[trial]\n",
    "            slow_est[trial+1] = As*slow_est[trial] + Bs*errors[trial]\n",
    "        else:\n",
    "            rotation = 0\n",
    "            errors[trial] = rotation_est[trial]\n",
    "        #print(errors[trial])\n",
    "            fast_est[trial+1] = Af*fast_est[trial] - Bf*errors[trial]\n",
    "            slow_est[trial+1] = As*slow_est[trial] - Bs*errors[trial]\n",
    "\n",
    "        rotation_est[trial+1] = fast_est[trial+1] + slow_est[trial+1]\n",
    "        #print (rotation_est)\n",
    "    errors[num_trials-1] = rotation_est[num_trials-1]\n",
    "    return errors, rotation_est, fast_est, slow_est\n",
    "\n",
    "def dual_model_gradual_transfer(num_trials, Af, Bf, As, Bs):\n",
    "    errors = np.zeros((num_trials))\n",
    "    fast_est = np.zeros((num_trials))\n",
    "    slow_est = np.zeros((num_trials))\n",
    "    rotation_est = np.zeros((num_trials))\n",
    "    rotation = 0\n",
    "    for trial in range(num_trials - 1):\n",
    "        if trial < 640:\n",
    "            if trial%64 == 0:\n",
    "                rotation = rotation + 10/90.0\n",
    "            if rotation > 1.0:\n",
    "                rotation = 1.0\n",
    "            errors[trial] = rotation - rotation_est[trial]\n",
    "            fast_est[trial+1] = Af*fast_est[trial] + Bf*errors[trial]\n",
    "            slow_est[trial+1] = As*slow_est[trial] + Bs*errors[trial]\n",
    "        else:\n",
    "            rotation = 0\n",
    "            errors[trial] = rotation_est[trial] \n",
    "            fast_est[trial+1] = Af*fast_est[trial] - Bf*errors[trial]\n",
    "            slow_est[trial+1] = As*slow_est[trial] - Bs*errors[trial]\n",
    "\n",
    "        rotation_est[trial+1] = fast_est[trial+1] + slow_est[trial+1]\n",
    "        #print (rotation_est)\n",
    "    errors[num_trials-1] = rotation_est[num_trials-1]\n",
    "\n",
    "    return errors, rotation_est, fast_est, slow_est\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Param Single state model with Transfer Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sudden(num_trials, A, B):\n",
    "    errors = np.zeros((num_trials))\n",
    "    rotation = 90/90.0\n",
    "    rotation_est = np.zeros((num_trials))\n",
    "    for trial in range(num_trials - 1):\n",
    "        if trial < 640:\n",
    "            rotation = 90/90.0\n",
    "            errors[trial] = rotation - rotation_est[trial]\n",
    "            rotation_est[trial+1] = A*rotation_est[trial] + B*errors[trial]\n",
    "        else:\n",
    "            rotation = 0\n",
    "            errors[trial] = rotation_est[trial]\n",
    "            rotation_est[trial+1] = A*rotation_est[trial] - B*errors[trial]\n",
    "        #errors[trial] = rotation - rotation_est[trial]\n",
    "    errors[num_trials-1] = rotation_est[num_trials-1]\n",
    "    return errors, rotation_est\n",
    "\n",
    "def model_gradual(num_trials, A, B):\n",
    "    errors = np.zeros((num_trials))\n",
    "    rotation_est = np.zeros((num_trials))\n",
    "    rotation = 0\n",
    "    for trial in range(num_trials - 1):\n",
    "        if trial < 640:\n",
    "            if trial%64 == 0:\n",
    "                rotation = rotation + 10/90.0\n",
    "            if rotation > 1.0:\n",
    "                rotation = 1.0\n",
    "            errors[trial] = rotation - rotation_est[trial]\n",
    "            rotation_est[trial+1] = A*rotation_est[trial] + B*errors[trial]\n",
    "        else:\n",
    "            rotation = 0\n",
    "            errors[trial] = rotation_est[trial]\n",
    "            rotation_est[trial+1] = A*rotation_est[trial] - B*errors[trial]\n",
    "\n",
    "    errors[num_trials-1] = rotation_est[num_trials-1]\n",
    "    return errors, rotation_est\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single State Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_residuals_sudden(params, num_trials, data_errors, train_indices):\n",
    "    model_errors = model_sudden(num_trials, params[0], params[1])[0]\n",
    "    model_errors_train = np.take(model_errors, train_indices)\n",
    "    data_errors_train = np.take(data_errors, train_indices)\n",
    "    #residual_error = np.sum(np.square(model_errors_train - data_errors_train))\n",
    "    residual_error = -2*sum(stat.norm.logpdf(data_errors_train, model_errors_train, params[2]))\n",
    "\n",
    "    if params[0] < 0 or params[1] < 0:\n",
    "        residual_error = residual_error + 10000000\n",
    "    if params[0] > 1 or params[1] > 1:\n",
    "        residual_error = residual_error + 10000000\n",
    "\n",
    "    return residual_error\n",
    "\n",
    "def single_residuals_gradual(params, num_trials, data_errors, train_indices):\n",
    "    model_errors = model_gradual(num_trials, params[0], params[1])[0]\n",
    "    model_errors_train = np.take(model_errors, train_indices)\n",
    "    data_errors_train = np.take(data_errors, train_indices)\n",
    "    #residual_error = np.sum(np.square(model_errors_train - data_errors_train))\n",
    "    residual_error = -2*sum(stat.norm.logpdf(data_errors_train, model_errors_train, params[2]))\n",
    "    if params[0] < 0 or params[1] < 0:\n",
    "        residual_error = residual_error + 10000000\n",
    "    if params[0] > 1 or params[1] > 1:\n",
    "        residual_error = residual_error + 10000000\n",
    "    return residual_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual State Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_residuals_sudden(params, num_trials, data_errors, train_indices):\n",
    "    model_errors = dual_model_sudden(num_trials, params[0], params[1], params[2], params[3])[0]\n",
    "    model_errors_train = np.take(model_errors, train_indices)\n",
    "    data_errors_train = np.take(data_errors, train_indices)\n",
    "    residual_error = -2*sum(stat.norm.logpdf(data_errors_train, model_errors_train, params[4]))\n",
    "    #residual_error = np.sum(np.square(model_errors_train - data_errors_train))\n",
    "    if params[0] > params[2]:\n",
    "        residual_error = residual_error + 10000000\n",
    "    if params[1] < params[3]:\n",
    "        residual_error = residual_error + 10000000\n",
    "    if params[0] < 0 or params[1] < 0 or params[2] < 0 or params[3] < 0:\n",
    "        residual_error = residual_error + 10000000\n",
    "    return residual_error\n",
    "\n",
    "def dual_residuals_gradual(params, num_trials, data_errors, train_indices):\n",
    "    model_errors = dual_model_gradual(num_trials, params[0], params[1], params[2], params[3])[0]\n",
    "    model_errors_train = np.take(model_errors, train_indices)\n",
    "    data_errors_train = np.take(data_errors, train_indices)\n",
    "    #residual_error = np.sum(np.square(model_errors_train - data_errors_train))\n",
    "    residual_error = -2*sum(stat.norm.logpdf(data_errors_train, model_errors_train, params[4]))\n",
    "    if params[0] > params[2]:\n",
    "        residual_error = residual_error + 10000000\n",
    "    if params[1] < params[3]:\n",
    "        residual_error = residual_error + 10000000\n",
    "    if params[0] < 0 or params[1] < 0 or params[2] < 0 or params[3] < 0:\n",
    "        residual_error = residual_error + 10000000\n",
    "    return residual_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_test_fit(participant, curvatures, num_fits, num_fit_trials):\n",
    "    Af = np.zeros((num_fits))\n",
    "    Bf = np.zeros((num_fits))\n",
    "    As = np.zeros((num_fits))\n",
    "    Bs = np.zeros((num_fits))\n",
    "    epsilon = np.zeros((num_fits))\n",
    "    V = np.zeros((num_fits))\n",
    "    train_length = num_fit_trials - np.floor(num_fit_trials/10.0)\n",
    "    train_indices = np.zeros((num_fits, train_length))\n",
    "    \n",
    "    for fit_parts in range(num_fits):\n",
    "        train_indices = np.random.choice(num_fit_trials, train_length, replace = False)\n",
    "        starting_points = np.array([[0.9, 0.3, 0.99, 0.01, 0.05]])\n",
    "        for initial_point in starting_points:\n",
    "            if participant%4 == 0 or participant%4 == 1:      \n",
    "                fits = scipy.optimize.basinhopping(residuals_sudden, x0 = [initial_point[0], initial_point[1], initial_point[2], initial_point[3], initial_point[4]], minimizer_kwargs={'args': (num_fit_trials, np.nan_to_num(np.ravel(curvatures[participant][1:]), nan = np.nanmedian(curvatures[participant][1:])), train_indices), 'method':'Nelder-Mead'})\n",
    "\n",
    "                Af[fit_parts] = fits.x[0]\n",
    "                Bf[fit_parts] = fits.x[1]\n",
    "                As[fit_parts] = fits.x[2]\n",
    "                Bs[fit_parts] = fits.x[3]\n",
    "                epsilon[fit_parts] = fits.x[4]\n",
    "                V[fit_parts] = fits.fun\n",
    "            else:\n",
    "                fits = scipy.optimize.basinhopping(residuals_gradual, x0 = [initial_point[0], initial_point[1], initial_point[2], initial_point[3], initial_point[4]], minimizer_kwargs={'args': (num_fit_trials, np.nan_to_num(np.ravel(curvatures[participant][1:]), nan = np.nanmedian(curvatures[participant][1:])), train_indices), 'method':'Nelder-Mead'})\n",
    "                Af[fit_parts] = fits.x[0]\n",
    "                Bf[fit_parts] = fits.x[1]\n",
    "                As[fit_parts] = fits.x[2]\n",
    "                Bs[fit_parts] = fits.x[3]\n",
    "                epsilon[fit_parts] = fits.x[4]\n",
    "                V[fit_parts] = fits.fun\n",
    "                \n",
    "            print (participant, V)\n",
    "    return Af, Bf, As, Bs, V, epsilon, train_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_test_fit(participant, curvatures, num_fits, num_fit_trials):\n",
    "    train_indices = np.random.choice(704, 634, replace = False)\n",
    "    for fit_parts in range(num_fits):\n",
    "\n",
    "        starting_points = np.array([[0.9, 0.2, 0.5]])\n",
    "        for initial_point in starting_points:\n",
    "            if participant%4 == 0 or participant%4 == 1:      \n",
    "                fits = scipy.optimize.basinhopping(residuals_sudden, x0 = [initial_point[0], initial_point[1], initial_point[2]], minimizer_kwargs={'args': (704, np.nan_to_num(np.ravel(curvatures[participant][1:]), nan = np.nanmedian(curvatures[participant][1:])), train_indices), 'method':'Nelder-Mead'})\n",
    "\n",
    "                A = fits.x[0]\n",
    "                B = fits.x[1]\n",
    "                epsilon = fits.x[2]\n",
    "                V = fits.fun\n",
    "            else:\n",
    "                fits = scipy.optimize.basinhopping(residuals_gradual, x0 = [initial_point[0], initial_point[1], initial_point[2]], minimizer_kwargs={'args': (704, np.nan_to_num(np.ravel(curvatures[participant][1:]), nan = np.nanmedian(curvatures[participant][1:])), train_indices), 'method':'Nelder-Mead'})\n",
    "                \n",
    "                A = fits.x[0]\n",
    "                B = fits.x[1]\n",
    "                epsilon = fits.x[2]\n",
    "                V = fits.fun\n",
    "            print (participant, V)\n",
    "    return A, B, V, epsilon, train_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Fit routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fits_dual(curvatures, num_trials, part_size):\n",
    "    func = partial(dual_test_fit, curvatures = curvatures, num_fits = 1, num_fit_trials = 704)\n",
    "    pool = Pool()\n",
    "    res = np.reshape(np.array(pool.map(func, range(60))), (60, 7))\n",
    "    return res   \n",
    "\n",
    "def run_fits_single(curvatures, num_trials, part_size):\n",
    "    func = partial(single_test_fit, curvatures = curvatures, num_fits = 1)\n",
    "    pool = Pool()\n",
    "    res = np.reshape(np.array(pool.map(func, range(60))), (60, 5))\n",
    "    return res   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
